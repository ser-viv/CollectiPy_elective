# ------------------------------------------------------------------------------
#  CollectiPy
#  Copyright (c) 2025 Fabio Oddi
#
#  This file is part of CollectyPy, released under the BSD 3-Clause License.
#  You may use, modify, and redistribute this file according to the terms of the
#  license. Attribution is required if this code is used in other works.
# ------------------------------------------------------------------------------

import math
import os, json, pickle, shutil, zipfile
from config import Config

class DataHandlingFactory():
    """Data handling factory."""
    @staticmethod
    def create_data_handling(config_elem: Config):
        """Create data handling."""
        if config_elem.arena.get("_id") in ("abstract", "none", None):
            return DataHandling(config_elem)
        else:
            return SpaceDataHandling(config_elem)

class DataHandling():
    """Data handling."""
    def __init__(self, config_elem: Config):
        """Initialize the instance."""
        results_cfg = config_elem.results or {}
        base_path = results_cfg.get("base_path") or "../data/"
        self.agent_specs = self._normalize_specs(results_cfg.get("agent_specs"))
        self.group_specs = self._normalize_specs(results_cfg.get("group_specs"))
        legacy_specs = self._normalize_specs(results_cfg.get("model_specs"))
        agent_specs_were_provided = "agent_specs" in results_cfg
        if not agent_specs_were_provided and not self.agent_specs:
            # Preserve the legacy behaviour: saving base agent states unless explicitly disabled.
            self.agent_specs = {"base"}
        if legacy_specs:
            if "spin_model" in legacy_specs:
                self.agent_specs.add("spin_model")
            if "graphs" in legacy_specs:
                self.group_specs.update({"graph_messages", "graph_detection", "graphs"})
            if "graph_messages" in legacy_specs:
                self.group_specs.add("graph_messages")
            if "graph_detection" in legacy_specs:
                self.group_specs.add("graph_detection")
        self.base_dump_enabled = "base" in self.agent_specs
        self.spin_dump_enabled = "spin_model" in self.agent_specs
        self.graph_messages_enabled = "graphs" in self.group_specs or "graph_messages" in self.group_specs
        self.graph_detection_enabled = "graphs" in self.group_specs or "graph_detection" in self.group_specs
        self.snapshots_per_second = self._parse_snapshot_rate(results_cfg.get("snapshots_per_second", 1))
        abs_base_path = os.path.join(os.path.abspath(""), base_path)
        os.makedirs(abs_base_path, exist_ok=True)
        existing = [d for d in os.listdir(abs_base_path) if d.startswith("config_folder_")]
        folder_id = len(existing)
        self.config_folder = os.path.join(abs_base_path, f"config_folder_{folder_id}")
        if os.path.exists(self.config_folder):
            raise Exception(f"Error config folder {self.config_folder} already present")
        os.mkdir(self.config_folder)
        with open(os.path.join(self.config_folder, "config.json"), "w") as f:
            json.dump(config_elem.__dict__, f, indent=4, default=str)
        self.agents_files = {}
        self.agent_spin_files = {}
        self.agent_name_order = []
        self.agent_lookup = {}
        self.agents_metadata = {}
        self.run_folder = None
        self._ticks_per_second = 1
        self._snapshot_offsets = [1]
        self._last_snapshot_tick = None
        self._graph_step_dirs = {}
        self._graphs_root = None

    def _normalize_specs(self, value):
        """Return a normalized set of model spec tokens."""
        if value is None:
            return set()
        if isinstance(value, str):
            iterable = [value]
        elif isinstance(value, (list, tuple, set)):
            iterable = value
        else:
            iterable = []
        specs = {str(item).strip().lower() for item in iterable if str(item).strip()}
        return specs

    def _parse_snapshot_rate(self, value):
        """Return a valid snapshot count per simulated second."""
        try:
            rate = int(value)
        except (TypeError, ValueError):
            rate = 1
        return max(1, min(2, rate))

    def _sanitize_tick_rate(self, ticks_per_second):
        """Ensure ticks per second is a positive integer."""
        try:
            value = int(ticks_per_second)
        except (TypeError, ValueError):
            value = 1
        return max(1, value)

    def _build_snapshot_offsets(self, ticks_per_second: int):
        """Return the list of tick offsets (within a second) where snapshots are taken."""
        ticks_per_second = max(1, ticks_per_second)
        offsets = set()
        for slot in range(1, self.snapshots_per_second + 1):
            raw = round(slot * ticks_per_second / self.snapshots_per_second)
            offsets.add(max(1, min(ticks_per_second, raw)))
        offsets.add(ticks_per_second)
        return sorted(offsets)

    def _prepare_graph_dirs(self):
        """Initialize per-step graph folders if requested."""
        self._graph_step_dirs = {}
        self._graphs_root = None
        if not (self.graph_messages_enabled or self.graph_detection_enabled):
            return
        graphs_root = os.path.join(self.run_folder, "graphs")
        os.makedirs(graphs_root, exist_ok=True)
        self._graphs_root = graphs_root
        if self.graph_messages_enabled:
            msg_dir = os.path.join(graphs_root, "messages")
            os.makedirs(msg_dir, exist_ok=True)
            self._graph_step_dirs["messages"] = msg_dir
        if self.graph_detection_enabled:
            det_dir = os.path.join(graphs_root, "detection")
            os.makedirs(det_dir, exist_ok=True)
            self._graph_step_dirs["detection"] = det_dir

    def _update_tick_rate(self, ticks_per_second):
        """Update the cached tick rate and snapshot schedule when needed."""
        if ticks_per_second is None:
            return
        sanitized = self._sanitize_tick_rate(ticks_per_second)
        if sanitized != self._ticks_per_second:
            self._ticks_per_second = sanitized
            self._snapshot_offsets = self._build_snapshot_offsets(self._ticks_per_second)

    def _should_capture_tick(self, tick: int, force: bool = False) -> bool:
        """Return True if the current tick should be captured."""
        if force:
            return True
        if tick is None:
            return False
        if tick <= 0:
            return False
        offsets = self._snapshot_offsets or [self._ticks_per_second]
        position_in_second = ((tick - 1) % max(1, self._ticks_per_second)) + 1
        return position_in_second in offsets

    def _finalize_graph_archives(self):
        """Zip per-step graph files (if any) and clean temporary folders."""
        for mode, dir_path in list(self._graph_step_dirs.items()):
            if not os.path.isdir(dir_path):
                continue
            archive_path = os.path.join(self.run_folder, f"{mode}_graphs.zip")
            if os.path.exists(archive_path):
                os.remove(archive_path)
            with zipfile.ZipFile(archive_path, "w", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zf:
                for root, _, files in os.walk(dir_path):
                    for filename in sorted(files):
                        abs_path = os.path.join(root, filename)
                        arcname = os.path.relpath(abs_path, self.run_folder)
                        zf.write(abs_path, arcname)
            shutil.rmtree(dir_path)
        if self._graphs_root and os.path.isdir(self._graphs_root) and not os.listdir(self._graphs_root):
            os.rmdir(self._graphs_root)
        self._graph_step_dirs = {}
        self._graphs_root = None

    def new_run(self, run: int, shapes, spins, metadata, ticks_per_second: int | None = None):
        """Create a new run."""
        self.run_folder = os.path.join(self.config_folder, f"run_{run}")
        if os.path.exists(self.run_folder):
            raise Exception(f"Error run folder {self.run_folder} already present")
        os.mkdir(self.run_folder)
        self.agents_files = {}
        self.agent_spin_files = {}
        self.agent_name_order = []
        self.agent_lookup = {}
        self.agents_metadata = metadata or {}
        self._ticks_per_second = self._sanitize_tick_rate(ticks_per_second)
        self._snapshot_offsets = self._build_snapshot_offsets(self._ticks_per_second)
        self._last_snapshot_tick = None
        self._prepare_graph_dirs()

    def save(self, shapes, spins, metadata, tick: int, ticks_per_second: int | None = None, force: bool = False):
        """Save value (override in subclasses)."""
        _ = (shapes, spins, metadata, tick, ticks_per_second, force)

    def close(self, shapes):
        """Close the component resources."""
        self._archive_run_folder()

    def _archive_run_folder(self):
        """Compress the current run folder and remove its original contents."""
        if self.run_folder is None or not os.path.isdir(self.run_folder):
            return
        zip_path = f"{self.run_folder}.zip"
        if os.path.exists(zip_path):
            os.remove(zip_path)
        base_dir = os.path.dirname(self.run_folder)
        with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED, compresslevel=9) as zf:
            for root, _, files in os.walk(self.run_folder):
                for filename in files:
                    abs_path = os.path.join(root, filename)
                    arcname = os.path.relpath(abs_path, base_dir)
                    zf.write(abs_path, arcname)
        shutil.rmtree(self.run_folder)
        self.run_folder = None

class SpaceDataHandling(DataHandling):
    """Space data handling."""
    def __init__(self, config_elem: Config):
        """Initialize the instance."""
        super().__init__(config_elem)

    def new_run(self, run: int, shapes, spins, metadata, ticks_per_second: int | None = None):
        """Create a new run."""
        super().new_run(run, shapes, spins, metadata, ticks_per_second)
        self.agent_name_order = []
        self.agent_lookup = {}
        if shapes is not None:
            for key, entities in shapes.items():
                for idx, entity in enumerate(entities):
                    agent_id = self._agent_identifier(key, idx, entity)
                    self.agent_lookup[(key, idx)] = agent_id
                    if agent_id not in self.agent_name_order:
                        self.agent_name_order.append(agent_id)
                    if self.base_dump_enabled:
                        file_path = os.path.join(self.run_folder, f"{agent_id}.pkl")
                        if os.path.exists(file_path):
                            raise Exception(f"Error: file {file_path} already exists")
                        file_handle = open(file_path, "wb")
                        pickler = pickle.Pickler(file_handle, protocol=pickle.HIGHEST_PROTOCOL)
                        header = ["tick", "x", "y", "z"]
                        pickler.dump({"type": "header", "value": header})
                        self.agents_files[(key, idx)] = {"handle": file_handle, "pickler": pickler}
                    if self.spin_dump_enabled:
                        spin_path = os.path.join(self.run_folder, f"{agent_id}_spins.pkl")
                        if os.path.exists(spin_path):
                            raise Exception(f"Error: file {spin_path} already exists")
                        spin_handle = open(spin_path, "wb")
                        spin_pickler = pickle.Pickler(spin_handle, protocol=pickle.HIGHEST_PROTOCOL)
                        spin_pickler.dump({"type": "header", "value": ["tick", "spins"]})
                        self.agent_spin_files[(key, idx)] = {"handle": spin_handle, "pickler": spin_pickler}
        self.agents_metadata = metadata or {}
        # Capture the bootstrap snapshot (tick 0) right away.
        if self.base_dump_enabled or self.spin_dump_enabled or self.graph_messages_enabled or self.graph_detection_enabled:
            self.save(shapes, spins, metadata, tick=0, ticks_per_second=self._ticks_per_second, force=True)

    def save(self, shapes, spins, metadata, tick: int, ticks_per_second: int | None = None, force: bool = False):
        """Save sampled data for the current tick."""
        if not (self.base_dump_enabled or self.spin_dump_enabled or self.graph_messages_enabled or self.graph_detection_enabled):
            return
        self._update_tick_rate(ticks_per_second)
        if tick is None:
            return
        spin_data = spins or {}
        self.agents_metadata = metadata or self.agents_metadata
        if self._last_snapshot_tick == tick:
            if not force:
                return
            # Already stored this tick; nothing else to do.
            return
        capture = self._should_capture_tick(tick, force=force)
        if not capture:
            return
        if self.base_dump_enabled and shapes is not None:
            for key, entities in shapes.items():
                for idx, entity in enumerate(entities):
                    entry = self.agents_files.get((key, idx))
                    if not entry:
                        continue
                    com = entity.center_of_mass()
                    row = [tick, com.x, com.y, com.z]
                    entry["pickler"].dump({"type": "row", "value": row})
        if self.spin_dump_enabled and self.agent_spin_files:
            for (key, idx), spin_entry in self.agent_spin_files.items():
                spin_values = self._resolve_spin_entry(spin_data.get(key), idx)
                spin_entry["pickler"].dump({"type": "row", "value": {"tick": tick, "spins": spin_values}})
        self._write_graph_snapshot(shapes, tick)
        self._last_snapshot_tick = tick

    def close(self, shapes):
        """Close the component resources."""
        if self.agents_files:
            for entry in self.agents_files.values():
                entry["handle"].flush()
                entry["handle"].close()
            self.agents_files.clear()
        if self.agent_spin_files:
            for entry in self.agent_spin_files.values():
                entry["handle"].flush()
                entry["handle"].close()
            self.agent_spin_files.clear()
        self._finalize_graph_archives()
        super().close(shapes)

    def _agent_identifier(self, key, idx, shape_obj):
        """Return a stable agent identifier for file names."""
        if shape_obj is not None:
            metadata = getattr(shape_obj, "metadata", None)
            if isinstance(metadata, dict):
                name = metadata.get("entity_name")
                if name:
                    return name
        return f"{key}_{idx}"

    def _resolve_spin_entry(self, spin_group, idx):
        """Return the spin payload for the given agent."""
        if not spin_group or idx >= len(spin_group):
            return None
        value = spin_group[idx][0]
        return value

    def _write_graph_snapshot(self, shapes, tick: int):
        """Persist per-step adjacency graphs (messages/detection)."""
        if not shapes:
            return
        if not (self.graph_messages_enabled or self.graph_detection_enabled):
            return
        if tick is None:
            return
        metadata = self.agents_metadata or {}
        agents = []
        for key, entities in shapes.items():
            group_meta = metadata.get(key, [])
            for idx, entity in enumerate(entities):
                agent_id = self.agent_lookup.get((key, idx))
                if not agent_id:
                    agent_id = self._agent_identifier(key, idx, entity)
                    self.agent_lookup[(key, idx)] = agent_id
                    if agent_id not in self.agent_name_order:
                        self.agent_name_order.append(agent_id)
                center = entity.center_of_mass()
                entry_meta = group_meta[idx] if idx < len(group_meta) else {}
                agents.append((agent_id, center, entry_meta))
        for mode in ("messages", "detection"):
            if mode == "messages" and not self.graph_messages_enabled:
                continue
            if mode == "detection" and not self.graph_detection_enabled:
                continue
            dir_path = self._graph_step_dirs.get(mode)
            if not dir_path:
                continue
            edges = self._compute_graph_edges(mode, agents)
            filename = os.path.join(dir_path, f"step_{tick:09d}.pkl")
            with open(filename, "wb") as fh:
                rows = [(name, name) for name in self.agent_name_order]
                rows.extend(edges)
                payload = {
                    "mode": mode,
                    "tick": tick,
                    "rows": rows,
                    "description": "Two-column edge list (self loops + directed edges)."
                }
                pickle.dump(payload, fh, protocol=pickle.HIGHEST_PROTOCOL)

    def _compute_graph_edges(self, mode: str, agents):
        """Compute adjacency edges for the requested mode."""
        edges = set()
        for i, (name_a, pos_a, meta_a) in enumerate(agents):
            for j, (name_b, pos_b, meta_b) in enumerate(agents):
                if i == j:
                    continue
                distance = math.dist((pos_a.x, pos_a.y), (pos_b.x, pos_b.y))
                if mode == "messages":
                    if self._can_message(meta_a, meta_b, distance):
                        edges.add((name_a, name_b))
                else:
                    if self._can_detect(meta_a, distance):
                        edges.add((name_a, name_b))
        return sorted(edges)

    @staticmethod
    def _can_message(meta_src, meta_dst, distance):
        """Return True if the source metadata allows messaging another agent at the given distance."""
        if not meta_src or not meta_src.get("msg_enable"):
            return False
        if not meta_dst:
            return False
        try:
            rng = float(meta_src.get("msg_comm_range", 0.0))
        except (TypeError, ValueError):
            rng = 0.0
        if rng <= 0:
            return False
        try:
            tx_rate = float(meta_src.get("msg_tx_rate", 0.0))
        except (TypeError, ValueError):
            tx_rate = 0.0
        if tx_rate <= 0.0:
            return False
        try:
            rx_rate = float(meta_dst.get("msg_rx_rate", 0.0))
        except (TypeError, ValueError):
            rx_rate = 0.0
        if rx_rate <= 0.0:
            return False
        return math.isinf(rng) or distance <= rng

    @staticmethod
    def _can_detect(meta, distance):
        """Return True if detection metadata allows sensing at the given distance."""
        if not meta:
            return False
        try:
            rng = float(meta.get("detection_range", math.inf))
        except (TypeError, ValueError):
            rng = math.inf
        if rng <= 0:
            return False
        try:
            freq = float(meta.get("detection_frequency", math.inf))
        except (TypeError, ValueError):
            freq = 0.0
        if freq <= 0.0:
            return False
        return math.isinf(rng) or distance <= rng
